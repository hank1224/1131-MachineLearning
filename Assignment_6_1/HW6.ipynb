{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SVM, Linear, Decision Tree do stacking\n",
    "2. NNIST 0~9 手寫辨識 CNN + LSTM 做成圖表的架構\n",
    "3. LSTM . RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 載入 Iris 資料集\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 分割資料集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定義基模型\n",
    "base_models = [\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('lr', LogisticRegression(max_iter=1000)),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "# 定義元模型\n",
    "class MetaModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MetaModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, 3)  # 3 classes for Iris dataset\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# 訓練基模型並生成其預測結果\n",
    "def train_base_models(base_models, X_train, y_train, X_val, y_val):\n",
    "    predictions = np.zeros((X_val.shape[0], len(base_models)))\n",
    "    for i, (name, model) in enumerate(base_models):\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions[:, i] = model.predict(X_val)\n",
    "    return predictions\n",
    "\n",
    "# 使用 K-fold 交叉驗證來生成基模型的預測結果\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "meta_features = np.zeros((X_train.shape[0], len(base_models)))\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    meta_features[val_index] = train_base_models(base_models, X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
    "\n",
    "# 訓練元模型\n",
    "meta_model = MetaModel(input_dim=len(base_models))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(meta_model.parameters(), lr=0.01)\n",
    "\n",
    "# 將 meta_features 和 y_train 轉換為 PyTorch 張量\n",
    "meta_features_tensor = torch.tensor(meta_features, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "# 訓練元模型\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    meta_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = meta_model(meta_features_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 使用基模型對測試集進行預測\n",
    "test_meta_features = train_base_models(base_models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 使用元模型對測試集進行最終預測\n",
    "meta_model.eval()\n",
    "test_meta_features_tensor = torch.tensor(test_meta_features, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    test_outputs = meta_model(test_meta_features_tensor)\n",
    "    _, test_preds = torch.max(test_outputs, 1)\n",
    "\n",
    "# 計算測試集上的準確率\n",
    "accuracy = accuracy_score(y_test, test_preds.numpy())\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 載入資料集\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 2. 資料前處理\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# 3. 訓練第一層模型\n",
    "base_models = [\n",
    "    ('svm', SVC(probability=True, random_state=42)),\n",
    "    ('lr', LogisticRegression(random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "# 4. 訓練第二層模型（元模型）\n",
    "meta_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# 5. 建立 Stacking 模型\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# 6. 訓練 Stacking 模型\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# 7. 評估模型性能\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Stacking Model Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# 8. 可視化結果\n",
    "def plot_decision_boundary(model, X, y, title):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', marker='o')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# 只用前兩個特徵做可視化\n",
    "X_train_vis = X_train[:, :2]\n",
    "X_test_vis = X_test[:, :2]\n",
    "\n",
    "for name, model in base_models:\n",
    "    model.fit(X_train_vis, y_train)\n",
    "    plot_decision_boundary(model, X_test_vis, y_test, f'{name} Decision Boundary')\n",
    "\n",
    "# 可視化 Stacking 模型\n",
    "stacking_model.fit(X_train_vis, y_train)\n",
    "plot_decision_boundary(stacking_model, X_test_vis, y_test, 'Stacking Decision Boundary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 加載MNIST數據集\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 將數據標準化到0-1之間\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# CNN模型\n",
    "cnn_input = layers.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(cnn_input)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "cnn_output = layers.Flatten()(x)\n",
    "\n",
    "# LSTM模型\n",
    "lstm_input = layers.Input(shape=(28, 28))\n",
    "y = layers.LSTM(128)(lstm_input)\n",
    "lstm_output = y\n",
    "\n",
    "# 特徵融合\n",
    "merged = layers.concatenate([cnn_output, lstm_output])\n",
    "\n",
    "# 全連接層\n",
    "z = layers.Dense(128, activation='relu')(merged)\n",
    "z = layers.Dense(10, activation='softmax')(z)\n",
    "\n",
    "# 定義最終模型\n",
    "model = models.Model(inputs=[cnn_input, lstm_input], outputs=z)\n",
    "\n",
    "# 編譯模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 將輸入數據適配模型的輸入格式\n",
    "x_train_cnn = x_train[..., tf.newaxis]  # 增加一個維度以適應CNN輸入\n",
    "x_train_lstm = x_train  # 保持原始形狀以適應LSTM輸入\n",
    "x_test_cnn = x_test[..., tf.newaxis]\n",
    "x_test_lstm = x_test\n",
    "\n",
    "# 訓練模型\n",
    "model.fit([x_train_cnn, x_train_lstm], y_train, epochs=10, batch_size=64, validation_data=([x_test_cnn, x_test_lstm], y_test))\n",
    "\n",
    "# 評估模型\n",
    "test_loss, test_acc = model.evaluate([x_test_cnn, x_test_lstm], y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
