{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Linear Regression with Neural Network\n",
    "\n",
    "Hi all, \n",
    "\n",
    "    Please complete following 2 tasks. \n",
    "\n",
    "1. Use the neural network concept to solve for the weights of linear regression. \n",
    "\n",
    "2. Plot the resulting residual plot.\n",
    "\n",
    "Additionally, you can [see the link](https://github.com/TommyHuang821/Deep-Learning-API-example/blob/master/TensorFlow/TF%20%E7%AF%84%E4%BE%8B%20II%20(Regression).md) for task 1. \n",
    "\n",
    "With warm regards,\n",
    "\n",
    "Stanley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 1\n",
    "\n",
    "Use the neural network concept to solve for the weights of linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成一些假數據\n",
    "np.random.seed(0)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# 轉換數據格式以適應TensorFlow\n",
    "X = tf.constant(X, dtype=tf.float32)\n",
    "y = tf.constant(y, dtype=tf.float32)\n",
    "\n",
    "# 建立線性回歸模型\n",
    "class LinearRegressionModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.w = tf.Variable(tf.random.normal([1, 1]), name='weight')\n",
    "        self.b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return tf.matmul(x, self.w) + self.b\n",
    "\n",
    "# 定義損失函數（均方誤差）\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# 建立模型實例\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# 定義優化器\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "# 訓練模型\n",
    "def train(model, X, y, optimizer, num_epochs=1000):\n",
    "    for epoch in range(num_epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X)\n",
    "            loss = mean_squared_error(y, y_pred)\n",
    "        gradients = tape.gradient(loss, [model.w, model.b])\n",
    "        optimizer.apply_gradients(zip(gradients, [model.w, model.b]))\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}: Loss: {loss.numpy()}')\n",
    "\n",
    "# 開始訓練\n",
    "train(model, X, y, optimizer)\n",
    "\n",
    "# 輸出最終的權重和偏置\n",
    "print(\"最終的權重：\", model.w.numpy())\n",
    "print(\"最終的偏置：\", model.b.numpy())\n",
    "\n",
    "# 預測\n",
    "y_pred = model(X)\n",
    "\n",
    "# 計算殘差\n",
    "residuals = y - y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 2\n",
    "\n",
    "Plot the resulting residual plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製殘差圖\n",
    "plt.scatter(X, residuals, color='blue', alpha=0.5)\n",
    "plt.hlines(y=0, xmin=X.numpy().min(), xmax=X.numpy().max(), colors='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
